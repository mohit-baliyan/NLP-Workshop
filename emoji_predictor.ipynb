{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print( type( emoji.UNICODE_EMOJI ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò†\n",
      "üëåüèª\n"
     ]
    }
   ],
   "source": [
    "print( emoji.emojize( \":angry_face:\" ) )\n",
    "\n",
    "print( emoji.emojize( \":OK_hand_light_skin_tone:\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( \"train_emoji.csv\", header = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love you mum</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stop saying bullshit</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>congratulations on your acceptance</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The assignment is too long</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I want to go play</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0  1   2     3\n",
       "0              never talk to me again  3 NaN   NaN\n",
       "1     I am proud of your achievements  2 NaN   NaN\n",
       "2      It is the worst day in my life  3 NaN   NaN\n",
       "3                    Miss you so much  0 NaN   [0]\n",
       "4                        food is life  4 NaN   NaN\n",
       "5                      I love you mum  0 NaN   NaN\n",
       "6                Stop saying bullshit  3 NaN   NaN\n",
       "7  congratulations on your acceptance  2 NaN   NaN\n",
       "8         The assignment is too long   3 NaN   NaN\n",
       "9                   I want to go play  1 NaN   [3]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head( n = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dict = {\n",
    "    \n",
    "    0 : \":beating_heart:\",\n",
    "    1 :\":baseball:\",\n",
    "    2 :\":beaming_face_with_smiling_eyes:\",\n",
    "    3 :\":disappointed_face:\",\n",
    "    4 :\":fork_and_knife:\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíì\n",
      "‚öæ\n",
      "üòÅ\n",
      "üòû\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for ix in emoji_dict.values():\n",
    "    \n",
    "    print( emoji.emojize( ix ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[0]\n",
    "\n",
    "Y_train = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,  = X_train.shape\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again\n"
     ]
    }
   ],
   "source": [
    "print( X_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòû\n"
     ]
    }
   ],
   "source": [
    "print( emoji.emojize( emoji_dict[Y_train[0]] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings( \"ignore\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert every sentence into a list of words\n",
    "\n",
    "for ix in range( 132 ) :\n",
    "    \n",
    "    X_train[ix] = X_train[ix].lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n"
     ]
    }
   ],
   "source": [
    "print( X_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs( glove_file ) :\n",
    "    \n",
    "    with open( glove_file, 'r', encoding='utf8' ) as f :\n",
    "        \n",
    "        words = set()\n",
    "        \n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f :\n",
    "            \n",
    "            line = line.strip().split()\n",
    "            \n",
    "            curr_word = line[0]\n",
    "            \n",
    "            words.add( curr_word )\n",
    "            \n",
    "            word_to_vec_map[curr_word] = np.array( line[1:], dtype = np.float64 )\n",
    "        \n",
    "        i = 1\n",
    "        \n",
    "        words_to_index = {}\n",
    "        \n",
    "        index_to_words = {}\n",
    "        \n",
    "        for w in sorted( words ) :\n",
    "            \n",
    "            words_to_index[w] = i\n",
    "            \n",
    "            index_to_words[i] = w\n",
    "            \n",
    "            i = i + 1\n",
    "            \n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs( \"glove.6B.50d.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.092086,  0.2571  , -0.58693 , -0.37029 ,  1.0828  , -0.55466 ,\n",
       "       -0.78142 ,  0.58696 , -0.58714 ,  0.46318 , -0.11267 ,  0.2606  ,\n",
       "       -0.26928 , -0.072466,  1.247   ,  0.30571 ,  0.56731 ,  0.30509 ,\n",
       "       -0.050312, -0.64443 , -0.54513 ,  0.86429 ,  0.20914 ,  0.56334 ,\n",
       "        1.1228  , -1.0516  , -0.78105 ,  0.29656 ,  0.7261  , -0.61392 ,\n",
       "        2.4225  ,  1.0142  , -0.17753 ,  0.4147  , -0.12966 , -0.47064 ,\n",
       "        0.3807  ,  0.16309 , -0.323   , -0.77899 , -0.42473 , -0.30826 ,\n",
       "       -0.42242 ,  0.055069,  0.38267 ,  0.037415, -0.4302  , -0.39442 ,\n",
       "        0.10511 ,  0.87286 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"happy\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vector( words ) :\n",
    "    \n",
    "    ans = word_to_vec_map[words[0]]\n",
    "    \n",
    "    for i in range( 1, len( words ) ) :\n",
    "        \n",
    "        ans = np.add( ans, word_to_vec_map[words[i]] )\n",
    "        \n",
    "    ans = ans/float( len( words ) )\n",
    "    \n",
    "    return ans    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = avg_vector( X_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.718460e-02,  1.743740e-02,  5.284300e-02, -4.368060e-01,\n",
       "        2.756132e-01, -1.426688e-01, -6.120520e-01,  4.716140e-01,\n",
       "       -6.059740e-01,  1.566594e-01, -8.662400e-02,  4.906620e-01,\n",
       "       -6.480320e-01, -1.612960e-01,  8.897200e-01,  4.867520e-01,\n",
       "        4.601260e-02, -8.363342e-02, -2.288840e-01, -4.151500e-01,\n",
       "       -1.140000e-02,  6.407600e-01,  5.954280e-01,  1.780868e-01,\n",
       "        7.128668e-01, -2.072760e+00, -3.161338e-01,  1.869920e-01,\n",
       "        6.583040e-01, -6.969300e-01,  3.172380e+00,  5.411100e-01,\n",
       "       -5.941440e-01, -3.028740e-01, -2.285386e-01, -2.899120e-01,\n",
       "        2.006040e-01,  1.053064e-01, -3.933000e-02, -4.483020e-01,\n",
       "       -1.353596e-01, -2.031200e-03, -2.454976e-01,  1.305460e-01,\n",
       "       -1.976000e-02,  2.025340e-02, -1.199070e-01, -2.522034e-01,\n",
       "       -2.197784e-01,  3.076060e-01])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numbers = np.zeros( ( 132, 50 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( X_train.shape[0] ):\n",
    "    \n",
    "    X_numbers[i] = avg_vector( X_train[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0971846 ,  0.0174374 ,  0.052843  , ..., -0.2522034 ,\n",
       "        -0.2197784 ,  0.307606  ],\n",
       "       [ 0.00563117,  0.59711333, -0.13939717, ..., -0.06701233,\n",
       "        -0.025773  ,  0.32180167],\n",
       "       [ 0.27343125,  0.33763875, -0.33053875, ..., -0.335001  ,\n",
       "         0.06524875, -0.04257963],\n",
       "       ...,\n",
       "       [ 0.29220562,  0.1533622 , -0.015246  , ...,  0.032272  ,\n",
       "         0.1313342 ,  0.472114  ],\n",
       "       [-0.00701397,  0.54196333, -0.19225433, ..., -0.80106333,\n",
       "        -0.20057967,  0.78087   ],\n",
       "       [-0.1149985 ,  0.6452325 , -0.39727   , ...,  0.142175  ,\n",
       "        -0.2057708 ,  0.5231    ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( X_numbers.shape )\n",
    "\n",
    "X_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Input,Activation\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build neural network\n",
    "\n",
    "model.add( Dense( 10, activation = 'relu', input_shape= ( 50, ) ) )\n",
    "\n",
    "model.add( Dense( 5, activation = 'softmax' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = 'adam',\n",
    "              \n",
    "              loss = 'categorical_crossentropy',\n",
    "              \n",
    "              metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132, 5)\n"
     ]
    }
   ],
   "source": [
    "print( Y_train.shape )\n",
    "\n",
    "Y_onehot = to_categorical( Y_train )\n",
    "\n",
    "print( Y_onehot.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print( Y_train[0] )\n",
    "\n",
    "print( Y_onehot[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 466us/step - loss: 1.6969 - accuracy: 0.1364\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 1.6792 - accuracy: 0.1515\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.6649 - accuracy: 0.1894\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.6521 - accuracy: 0.2197\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.6418 - accuracy: 0.2273\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.6291 - accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 1.6205 - accuracy: 0.2652\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.6115 - accuracy: 0.2727\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 92us/step - loss: 1.6026 - accuracy: 0.2727\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 1.5941 - accuracy: 0.2955\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 1.5858 - accuracy: 0.2879\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 96us/step - loss: 1.5764 - accuracy: 0.2879\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 1.5666 - accuracy: 0.2879\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 1.5561 - accuracy: 0.3030\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 40us/step - loss: 1.5465 - accuracy: 0.3182\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.5364 - accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 45us/step - loss: 1.5266 - accuracy: 0.3409\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 53us/step - loss: 1.5168 - accuracy: 0.3409\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 1.5073 - accuracy: 0.3409\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 91us/step - loss: 1.4961 - accuracy: 0.3712\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 1.4866 - accuracy: 0.3636\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 42us/step - loss: 1.4771 - accuracy: 0.3485\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.4681 - accuracy: 0.3636\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 1.4580 - accuracy: 0.3636\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 1.4481 - accuracy: 0.3712\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 1.4369 - accuracy: 0.3788\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 1.4275 - accuracy: 0.3939\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 1.4174 - accuracy: 0.4015\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.4082 - accuracy: 0.4167\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 116us/step - loss: 1.3992 - accuracy: 0.4242\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.3906 - accuracy: 0.4242\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 1.3840 - accuracy: 0.4242\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 1.3758 - accuracy: 0.4470\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.3676 - accuracy: 0.4470\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 1.3594 - accuracy: 0.4470\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 1.3513 - accuracy: 0.4545\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 1.3432 - accuracy: 0.4621\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.3352 - accuracy: 0.4697\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.3279 - accuracy: 0.4697\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 1.3197 - accuracy: 0.4773\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 1.3134 - accuracy: 0.4924\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 1.3057 - accuracy: 0.5152\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 1.2987 - accuracy: 0.5303\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 1.2921 - accuracy: 0.5530\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 1.2855 - accuracy: 0.5606\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 1.2785 - accuracy: 0.5833\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 1.2713 - accuracy: 0.5833\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 1.2640 - accuracy: 0.5682\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 107us/step - loss: 1.2565 - accuracy: 0.5682\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.2488 - accuracy: 0.5606\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 1.2411 - accuracy: 0.5606\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 52us/step - loss: 1.2343 - accuracy: 0.5606\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 111us/step - loss: 1.2274 - accuracy: 0.5530\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 1.2206 - accuracy: 0.5606\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 1.2132 - accuracy: 0.5530\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 48us/step - loss: 1.2065 - accuracy: 0.5606\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.2005 - accuracy: 0.5530\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 131us/step - loss: 1.1940 - accuracy: 0.5227\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.1884 - accuracy: 0.5152\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 1.1820 - accuracy: 0.5455\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 50us/step - loss: 1.1763 - accuracy: 0.5606\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 1.1697 - accuracy: 0.5833\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 1.1630 - accuracy: 0.5682\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 118us/step - loss: 1.1569 - accuracy: 0.5682\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.1498 - accuracy: 0.5758\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 1.1432 - accuracy: 0.5833\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.1372 - accuracy: 0.5909\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 1.1309 - accuracy: 0.5833\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 1.1252 - accuracy: 0.5833\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 1.1191 - accuracy: 0.5909\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.1140 - accuracy: 0.5909\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 1.1079 - accuracy: 0.5909\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 82us/step - loss: 1.1001 - accuracy: 0.5985\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 1.0966 - accuracy: 0.5985\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.0914 - accuracy: 0.6136\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.0853 - accuracy: 0.6212\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.0793 - accuracy: 0.5985\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.0740 - accuracy: 0.5985\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.0701 - accuracy: 0.6061\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 53us/step - loss: 1.0644 - accuracy: 0.6136\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.0582 - accuracy: 0.6136\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 95us/step - loss: 1.0531 - accuracy: 0.6288\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.0471 - accuracy: 0.6439\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 1.0418 - accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 102us/step - loss: 1.0359 - accuracy: 0.6591\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 1.0307 - accuracy: 0.6591\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 51us/step - loss: 1.0269 - accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.0227 - accuracy: 0.6742\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 1.0167 - accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.0108 - accuracy: 0.6818\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 1.0049 - accuracy: 0.6894\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 0.9991 - accuracy: 0.6742\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.9928 - accuracy: 0.6894\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.9866 - accuracy: 0.6818\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 0.9811 - accuracy: 0.6591\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 53us/step - loss: 0.9753 - accuracy: 0.6515\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.9703 - accuracy: 0.6591\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.9645 - accuracy: 0.6591\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.9592 - accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.9534 - accuracy: 0.6742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fbf2c136f60>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( X_numbers, Y_onehot, epochs = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['congratulations', 'on', 'your', 'acceptance']\n"
     ]
    }
   ],
   "source": [
    "print( data[0][7] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.argmax( model.predict( X_numbers ), axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3\n",
      "1    2\n",
      "2    3\n",
      "3    0\n",
      "4    4\n",
      "5    0\n",
      "6    3\n",
      "7    2\n",
      "8    3\n",
      "9    1\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print( Y_train[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( output == Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "[[ 0.2047575   0.4665125  -0.39385825 -0.21400375  0.5693875   0.19566\n",
      "  -0.327045   -0.2054374  -0.4126725   0.65301189 -0.3267025   0.653345\n",
      "  -0.642835    0.0626755   1.1503925   0.0891825   0.2911375   0.3365475\n",
      "  -0.33327625 -0.2663675  -0.027435    0.65283     0.4776025   0.38726075\n",
      "   0.9074375  -1.81335    -1.2968875   0.21994     0.696095   -0.74308275\n",
      "   3.187125    0.273342   -0.18172    -0.1216975  -0.20048825 -0.0903625\n",
      "   0.1265975   0.01179    -0.1867775  -0.607775   -0.12607333  0.258237\n",
      "  -0.2903175  -0.08328534 -0.193961    0.18942425  0.069061   -0.6600925\n",
      "  -0.18246     0.6113375 ]]\n"
     ]
    }
   ],
   "source": [
    "text = \"i love this movie\"\n",
    "\n",
    "avg_v = avg_vector( text.split() )\n",
    "\n",
    "print( avg_v.shape )\n",
    "\n",
    "avg_v = avg_v.reshape( 1, 50 )\n",
    "\n",
    "print( avg_v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_label_predict = np.argmax( model.predict( avg_v ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "üòÅ\n"
     ]
    }
   ],
   "source": [
    "print( emoji_label_predict )\n",
    "\n",
    "print( emoji.emojize( emoji_dict[emoji_label_predict] ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
